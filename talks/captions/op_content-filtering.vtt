WEBVTT

slide-1
00:00:09.616 --> 00:00:11.606
<v ->Hello, my name is Oleksandr Paraska.</v>

2
00:00:11.606 --> 00:00:13.776
I work at Eyeo GmbH. It's a company

3
00:00:13.776 --> 00:00:17.276
behind the popular browser extension AdBlock Plus.

4
00:00:17.276 --> 00:00:19.546
I will present the use cases for machine learning

5
00:00:19.546 --> 00:00:21.136
that we have encountered while working

6
00:00:21.136 --> 00:00:24.386
on a problem of content filtering on the web.

7
00:00:24.386 --> 00:00:27.686
Slide one. One of the motivations

8
00:00:27.686 --> 00:00:29.386
that we have behind this presentation

9
00:00:29.386 --> 00:00:30.876
is to argue that our use case

10
00:00:30.876 --> 00:00:34.116
should be represented within Web Neural Networks API.

11
00:00:34.116 --> 00:00:36.826
I hope this will be useful for W3C group,

12
00:00:36.826 --> 00:00:41.129
and I hope we can have a discussion after that sometime.

slide-2
00:00:42.226 --> 00:00:43.966
Slide two. So before I start,

14
00:00:43.966 --> 00:00:46.626
I quickly wanted to maybe give a short overview

15
00:00:46.626 --> 00:00:48.686
how content filtering on the web works now,

16
00:00:48.686 --> 00:00:50.376
and then where does machine learning

17
00:00:50.376 --> 00:00:52.246
fit in into that scenario?

18
00:00:52.246 --> 00:00:54.926
So right now, there is a community of filter list authors

19
00:00:54.926 --> 00:00:58.216
who craft these filter lists, filter rules

20
00:00:58.216 --> 00:01:00.346
that define what needs to be blocked on the web.

21
00:01:00.346 --> 00:01:02.596
And then there is a separate software

22
00:01:02.596 --> 00:01:04.116
that downloads those filter rules.

23
00:01:04.116 --> 00:01:07.586
And then when the user uses the software

24
00:01:07.586 --> 00:01:08.496
to browse the internet,

25
00:01:08.496 --> 00:01:11.156
only the filtered content is rendered.

26
00:01:11.156 --> 00:01:12.546
Essentially, there are two ways

27
00:01:12.546 --> 00:01:15.016
you can block content on the web.

28
00:01:15.016 --> 00:01:16.966
There is network level blocking,

29
00:01:16.966 --> 00:01:20.076
and there is DOM level blocking I would say.

30
00:01:20.076 --> 00:01:22.024
Network level blocking is essentially

31
00:01:22.024 --> 00:01:23.756
a URL classification problem,

32
00:01:23.756 --> 00:01:25.482
where you have a list of URLs,

33
00:01:25.482 --> 00:01:27.866
maybe with some metadata for each URL.

34
00:01:27.866 --> 00:01:29.526
And then you want to understand

35
00:01:29.526 --> 00:01:31.876
if the specific URL should be blocked or not.

36
00:01:31.876 --> 00:01:34.286
And the key point here that I wanted to bring up

37
00:01:34.286 --> 00:01:37.316
is that the network level blocking

38
00:01:37.316 --> 00:01:38.876
is not the use case that we see

39
00:01:38.876 --> 00:01:42.146
for Web Neural Networks API.

40
00:01:42.146 --> 00:01:45.646
So we would like to talk only about DOM level blocking.

41
00:01:45.646 --> 00:01:48.026
We have an experiment with network level blocking

42
00:01:48.026 --> 00:01:48.976
with using machine learning,

43
00:01:48.976 --> 00:01:50.526
but what we found out is that

44
00:01:50.526 --> 00:01:52.596
it's at least 50 times slower

45
00:01:52.596 --> 00:01:54.966
than our current implementations.

46
00:01:54.966 --> 00:01:57.126
And also it's not clear

47
00:01:57.126 --> 00:01:58.696
if there are any benefits of using it.

48
00:01:58.696 --> 00:02:02.086
So that's why we want to focus only on DOM level blocking.

49
00:02:02.086 --> 00:02:03.475
That being said, there is already

50
00:02:03.475 --> 00:02:07.916
implementation of machine learning for a similar technique.

51
00:02:07.916 --> 00:02:10.156
And then Safari Intelligent Tracking Protection

52
00:02:10.156 --> 00:02:13.506
is probably the best and the most widely used

53
00:02:13.506 --> 00:02:16.136
implementation of machine learning for content filtering.

54
00:02:16.136 --> 00:02:20.579
So that's something that is definitely of interest for us.

slide-3
00:02:22.076 --> 00:02:26.278
Slide three. So about content blocking on the web,

56
00:02:26.278 --> 00:02:28.213
there is DOM level ad blocking,

57
00:02:28.213 --> 00:02:32.376
and that means that when you have a network request,

58
00:02:32.376 --> 00:02:34.826
which delivers both an ad and content,

59
00:02:34.826 --> 00:02:36.666
you cannot just block the network request

60
00:02:36.666 --> 00:02:38.466
because you will also block the content.

61
00:02:38.466 --> 00:02:40.056
Obviously, you have to deal with the ad

62
00:02:40.056 --> 00:02:43.276
then on the higher level, on a DOM level,

63
00:02:43.276 --> 00:02:45.066
and there you have multiple options.

64
00:02:45.066 --> 00:02:47.656
You can either apply a CSS selector

65
00:02:47.656 --> 00:02:49.676
to hide the specific element,

66
00:02:49.676 --> 00:02:52.226
or you can run some JavaScript code

67
00:02:52.226 --> 00:02:55.546
so that you can identify which element to hide.

68
00:02:55.546 --> 00:03:00.086
And then as the escalation of advertisers

69
00:03:00.086 --> 00:03:02.833
and ad-blockers continued,

70
00:03:02.833 --> 00:03:04.026
it became clear

71
00:03:04.026 --> 00:03:06.126
that just CSS selectors are often not enough,

72
00:03:06.126 --> 00:03:09.686
and you have to move up your game

73
00:03:09.686 --> 00:03:12.426
for JavaScript code further and further.

74
00:03:12.426 --> 00:03:14.936
So recently, we have deployed the machine learning model

75
00:03:14.936 --> 00:03:19.426
that is running on some websites to block advertising.

76
00:03:19.426 --> 00:03:21.906
So that's why we wanted to talk about

77
00:03:21.906 --> 00:03:24.906
our use case for Web Neural Networks API.

78
00:03:24.906 --> 00:03:25.946
Essentially, at the DOM level,

79
00:03:25.946 --> 00:03:27.506
ad blocking means that you need to

80
00:03:27.506 --> 00:03:29.646
find relevant features on the website,

81
00:03:29.646 --> 00:03:30.776
and you need to classify

82
00:03:30.776 --> 00:03:33.156
which elements need to be hidden

83
00:03:33.156 --> 00:03:34.796
based on those features.

84
00:03:34.796 --> 00:03:38.386
And then you have the regular features in the HTML world,

85
00:03:38.386 --> 00:03:41.919
which are class names, IDs, and so on.

86
00:03:41.919 --> 00:03:46.046
But machine learning brings you a more powerful language

87
00:03:46.046 --> 00:03:47.096
to classify elements.

88
00:03:47.096 --> 00:03:51.626
And I wanted to bring up at least two more ways

89
00:03:51.626 --> 00:03:54.516
we can classify elements with machine learning.

slide-4
00:03:54.516 --> 00:03:59.346
Slide four. So the most obvious way to classify elements

91
00:03:59.346 --> 00:04:00.306
once you have machine learning

92
00:04:00.306 --> 00:04:02.176
is the perceptual way,

93
00:04:02.176 --> 00:04:04.726
where the recent evolution in machine learning

94
00:04:04.726 --> 00:04:08.826
gave us more tools and understanding

95
00:04:08.826 --> 00:04:11.686
that we now are able to target elements

96
00:04:11.686 --> 00:04:15.556
based on how they look, not by their metadata.

97
00:04:15.556 --> 00:04:17.456
And so that means that you can just look at the image

98
00:04:17.456 --> 00:04:18.399
and maybe predict if there's something

99
00:04:18.399 --> 00:04:20.086
that is an ad or not an ad.

100
00:04:20.086 --> 00:04:23.176
And we have implemented similar algorithm

101
00:04:23.176 --> 00:04:24.796
to work in our extension.

102
00:04:24.796 --> 00:04:26.236
We didn't use machine learning for that.

103
00:04:26.236 --> 00:04:29.336
We only used the perceptual hashing.

104
00:04:29.336 --> 00:04:31.266
And perceptual hashing essentially is a technique

105
00:04:31.266 --> 00:04:33.346
that will give you a similar hash

106
00:04:33.346 --> 00:04:36.006
to images that look similar.

107
00:04:36.006 --> 00:04:38.026
And we have discovered that yes, it works

108
00:04:38.026 --> 00:04:40.776
and most websites that we want to apply this,

109
00:04:40.776 --> 00:04:44.976
the inventory of ad images is fairly limited.

110
00:04:44.976 --> 00:04:48.326
So we can list all the images or all the hashes,

111
00:04:48.326 --> 00:04:51.116
and we can apply these filters.

112
00:04:51.116 --> 00:04:52.776
However, we stumbled upon a problem

113
00:04:52.776 --> 00:04:56.016
where there is a canvas tainting issue

114
00:04:56.016 --> 00:04:58.056
where we are not able to have

115
00:04:58.056 --> 00:05:01.186
access to raw data of the images

116
00:05:01.186 --> 00:05:03.716
if the website owner does not allow us

117
00:05:03.716 --> 00:05:06.026
to have access.

118
00:05:06.026 --> 00:05:07.566
That's only an issue in Chrome,

119
00:05:07.566 --> 00:05:09.360
but it's still a big issue.

120
00:05:09.360 --> 00:05:11.863
In Firefox, we have a way around it.

121
00:05:11.863 --> 00:05:14.026
And so the question now is

122
00:05:15.172 --> 00:05:16.656
should there be something

123
00:05:16.656 --> 00:05:20.096
in Web Neural Networks API or in general

124
00:05:20.096 --> 00:05:22.876
that allows machine learning models

125
00:05:22.876 --> 00:05:26.456
to run on these images that are maybe tainted,

126
00:05:26.456 --> 00:05:30.094
but if the model does not produce or leaks any information

127
00:05:30.094 --> 00:05:34.336
to the user, then maybe that should be fine.

128
00:05:34.336 --> 00:05:36.056
And that's just the question I wanted to raise,

129
00:05:36.056 --> 00:05:38.579
and maybe we can discuss it moving forward.

130
00:05:39.566 --> 00:05:40.926
And then I would like to briefly

131
00:05:40.926 --> 00:05:42.636
go into the second kind of features

132
00:05:42.636 --> 00:05:47.636
that you could use for the element hiding on the web,

133
00:05:48.507 --> 00:05:50.336
and that is structural features.

134
00:05:50.336 --> 00:05:52.276
And the reason why we want to use structural features

135
00:05:52.276 --> 00:05:55.060
is because the image they show here,

136
00:05:55.060 --> 00:05:58.426
it's an image from the paper Percival

137
00:05:58.426 --> 00:06:01.356
where they have instrumented the Chromium browser

138
00:06:03.646 --> 00:06:06.166
to run an inference on every image

139
00:06:06.166 --> 00:06:08.986
that is being rendered by the rendering pipeline.

140
00:06:08.986 --> 00:06:11.836
And they are essentially classifying every image

141
00:06:11.836 --> 00:06:13.916
in the rendering pipeline, and that seems to work.

142
00:06:13.916 --> 00:06:16.706
But what you clearly can see from the paper

143
00:06:16.706 --> 00:06:19.776
is that it's not possible to just classify

144
00:06:19.776 --> 00:06:20.976
based on image data alone,

145
00:06:20.976 --> 00:06:23.166
because same image can be both an ad,

146
00:06:23.166 --> 00:06:24.606
and not an ad based on the context.

147
00:06:24.606 --> 00:06:26.026
So you need to have some context,

148
00:06:26.026 --> 00:06:29.106
which means you have to have structural data around it.

149
00:06:29.106 --> 00:06:31.196
And that's the second kind of features

150
00:06:31.196 --> 00:06:34.366
that you would want to use, the structural data.

slide-5
00:06:34.366 --> 00:06:36.646
Slide five. Structural data is important

152
00:06:36.646 --> 00:06:40.296
because it can be used as a feature of its own.

153
00:06:40.296 --> 00:06:42.256
For example, on one of the social networks you have,

154
00:06:42.256 --> 00:06:44.616
you can see how the sponsored label

155
00:06:44.616 --> 00:06:46.216
is being rendered by

156
00:06:46.216 --> 00:06:49.886
a whole bunch of spans and obfuscations,

157
00:06:49.886 --> 00:06:51.546
which are essentially impossible

158
00:06:51.546 --> 00:06:53.606
to pinpoint using the CSS selectors.

159
00:06:53.606 --> 00:06:56.596
So you have to use some other clever techniques.

160
00:06:56.596 --> 00:06:58.116
One of the techniques that you can use

161
00:06:58.116 --> 00:07:01.656
is that you can build a graph of this element

162
00:07:01.656 --> 00:07:03.366
of the whole post I would say,

163
00:07:03.366 --> 00:07:06.133
and then build a graph of a ad or not an ad.

164
00:07:06.133 --> 00:07:07.586
And then you will have, you will-

165
00:07:07.586 --> 00:07:09.526
should be able to classify if something is an ad,

166
00:07:09.526 --> 00:07:11.256
just purely based on the structure,

167
00:07:11.256 --> 00:07:13.586
because hopefully non ads

168
00:07:13.586 --> 00:07:17.316
would not have this obfuscation built in,

169
00:07:17.316 --> 00:07:18.826
or there would be other features

170
00:07:18.826 --> 00:07:21.646
that structurally are different.

171
00:07:21.646 --> 00:07:23.166
And that's maybe the key insight

172
00:07:23.166 --> 00:07:26.086
that we wanted to communicate here

173
00:07:26.086 --> 00:07:27.836
that structural information

174
00:07:27.836 --> 00:07:29.266
and running machine learning models

175
00:07:29.266 --> 00:07:32.246
on structural information is very useful in general.

176
00:07:32.246 --> 00:07:34.066
And also it's very useful for

177
00:07:34.066 --> 00:07:36.076
our purposes of content filtering in the web.

slide-6
00:07:36.076 --> 00:07:38.306
The way we see structural information here

179
00:07:38.306 --> 00:07:40.846
is that each DOM is a tree,

180
00:07:40.846 --> 00:07:43.076
so we can represent it as adjacency matrix.

181
00:07:43.076 --> 00:07:45.066
So you can see that here,

182
00:07:45.066 --> 00:07:49.723
for example, a &lt;div&gt; is moved to a top of the tree

183
00:07:49.723 --> 00:07:53.536
and then you have the leaves there as &lt;p&gt; and &lt;h1&gt;.

184
00:07:53.536 --> 00:07:55.846
And then because you represented the structure

185
00:07:55.846 --> 00:07:56.906
as adjacency matrix,

186
00:07:56.906 --> 00:07:59.336
it also can represent the features of each node

187
00:07:59.336 --> 00:08:01.826
as a separate matrix, a feature matrix.

188
00:08:01.826 --> 00:08:05.796
So for example, a &lt;div&gt; is number 29 in our use case.

189
00:08:05.796 --> 00:08:09.256
So then we say that 29 is something

190
00:08:09.256 --> 00:08:11.036
that you want to have here

191
00:08:11.036 --> 00:08:12.776
as the feature for first element,

192
00:08:12.776 --> 00:08:13.806
and so on and so on.

193
00:08:13.806 --> 00:08:16.376
So you can imagine that type of an element,

194
00:08:16.376 --> 00:08:17.506
is only one kind of a feature.

195
00:08:17.506 --> 00:08:19.966
You can have as many features as you want.

196
00:08:19.966 --> 00:08:22.046
And the more features that you have,

197
00:08:22.046 --> 00:08:24.206
the probably the slower the algorithm will be,

198
00:08:24.206 --> 00:08:27.276
but essentially that gives you

199
00:08:27.276 --> 00:08:31.826
a lot of power to target these specific elements.

200
00:08:31.826 --> 00:08:33.376
So once you are able to work

201
00:08:33.376 --> 00:08:35.536
with the data like this, you are able to either,

202
00:08:35.536 --> 00:08:37.846
solve graph isomorphism problems,

203
00:08:37.846 --> 00:08:41.076
or you are able to solve node classification problems.

204
00:08:41.076 --> 00:08:43.986
And those are the two things that graph convolution neural networks

205
00:08:43.986 --> 00:08:45.646
are particularly good at.

206
00:08:45.646 --> 00:08:47.226
And that those are the things

207
00:08:47.226 --> 00:08:49.216
that we are already experimenting with.

208
00:08:49.216 --> 00:08:51.556
So we have a code that is in our extension already

209
00:08:51.556 --> 00:08:53.414
that we are able to run,

210
00:08:53.414 --> 00:08:56.886
that is already using a built-in machine learning model

211
00:08:56.886 --> 00:09:00.969
to classify ads on social networks,

212
00:09:00.969 --> 00:09:04.426
based on purely structural data.

slide-7
00:09:04.426 --> 00:09:06.816
And on slide seven, I wanted to also communicate

214
00:09:06.816 --> 00:09:09.989
that it's not just us who work on these structural problems.

215
00:09:10.936 --> 00:09:13.176
There is a recent paper of AdGraph

216
00:09:13.176 --> 00:09:16.276
that is looking for a very similar thing.

217
00:09:16.276 --> 00:09:17.966
There they are using an instrumented

218
00:09:17.966 --> 00:09:19.876
Chromium browser to produce graphs.

219
00:09:19.876 --> 00:09:22.276
And then they are classifying those graphs

220
00:09:22.276 --> 00:09:24.946
based on the custom extracted features.

221
00:09:24.946 --> 00:09:25.996
So maybe in this case,

222
00:09:25.996 --> 00:09:28.146
they're not using the graph convolution neural networks,

223
00:09:28.146 --> 00:09:31.576
but the problem of running machine learning on graphs

224
00:09:31.576 --> 00:09:35.076
on the web is a very, very fruitful one.

225
00:09:35.076 --> 00:09:37.456
And that's what we wanted to communicate

226
00:09:37.456 --> 00:09:39.026
in this presentation.

slide-8
00:09:39.026 --> 00:09:42.856
And on slide eight, I wanted to maybe finalize

228
00:09:42.856 --> 00:09:45.247
by saying that it's very fruitful

229
00:09:45.247 --> 00:09:47.816
to look at the DOM as a graph.

230
00:09:47.816 --> 00:09:50.176
However, it's not a static graph, it's a dynamic graph

231
00:09:50.176 --> 00:09:51.826
because every mutation of an element

232
00:09:51.826 --> 00:09:53.526
changes that graph.

233
00:09:53.526 --> 00:09:56.256
So it's also useful to look at

234
00:09:56.256 --> 00:09:58.142
the filtering of those mutation

235
00:09:58.142 --> 00:10:00.306
as a machine learning problem,

236
00:10:00.306 --> 00:10:02.176
or maybe to look at the whole problem

237
00:10:02.176 --> 00:10:05.836
as a problem of dynamic graph classification.

238
00:10:05.836 --> 00:10:08.906
And in that case, we wanted to see

239
00:10:08.906 --> 00:10:11.400
if there are any other techniques

240
00:10:11.400 --> 00:10:13.376
that the community would like

241
00:10:13.376 --> 00:10:16.256
to embed into Web Neural Networks API.

242
00:10:16.256 --> 00:10:17.886
Then I also wanted to say that

243
00:10:17.886 --> 00:10:19.336
we already have this code running,

244
00:10:19.336 --> 00:10:21.406
and then if you're interested to have a look,

245
00:10:21.406 --> 00:10:23.066
we have a model, a pre-trained model there,

246
00:10:23.066 --> 00:10:25.196
and also the code that we're using there.

247
00:10:25.196 --> 00:10:28.006
And lastly, I wanted to say that,

248
00:10:28.006 --> 00:10:30.006
as I started with that,

249
00:10:30.006 --> 00:10:31.986
everything starts with the community of people

250
00:10:31.986 --> 00:10:33.063
who write the filter lists.

251
00:10:33.063 --> 00:10:34.626
And we certainly want to ensure

252
00:10:34.626 --> 00:10:36.476
that the community of people as always

253
00:10:36.476 --> 00:10:39.736
is also able to maintain the models.

254
00:10:39.736 --> 00:10:42.306
So for that, we are very interested

255
00:10:42.306 --> 00:10:44.426
in federated learning problems and

256
00:10:44.426 --> 00:10:46.306
how they relate to Web Neural Networks.

257
00:10:46.306 --> 00:10:49.516
And we have experimented with TFJS a little bit,

258
00:10:49.516 --> 00:10:51.126
but we wanted to understand

259
00:10:51.126 --> 00:10:53.186
how Web Neural Networks API

260
00:10:53.186 --> 00:10:56.136
would interact with federated learning problems.

261
00:10:56.136 --> 00:10:58.716
And on that, I will end.

slide-9
00:10:58.716 --> 00:10:59.716
Thank you very much.

